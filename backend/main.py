# backend/main.py
# =========================
# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë©”ì¸ íŒŒì¼
import os
import json
from dotenv import load_dotenv

# Load environment variables from .env file (if exists)
env_path = os.path.join(os.path.dirname(__file__), 'env', '.env')
if os.path.exists(env_path):
    load_dotenv(dotenv_path=env_path)

import subprocess
import tempfile
import shutil
from fastapi import FastAPI, HTTPException, Depends, Security, WebSocket, WebSocketDisconnect, Request
from fastapi.security.api_key import APIKeyHeader
from pydantic import BaseModel
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, Session
from typing import List, Optional
from datetime import datetime
import google.generativeai as genai
from models import Base, Deployment, DeploymentStatus, DataSource
from fastapi.middleware.cors import CORSMiddleware # Import CORSMiddleware

from fastapi.responses import StreamingResponse, FileResponse
from rag_service import rag_service_instance
import asyncio
from io import BytesIO

# Markdown to PDF conversion (optional import)
try:
    from markdown_pdf import MarkdownPdf, Section
    HAS_MARKDOWN_PDF = True
except ImportError:
    HAS_MARKDOWN_PDF = False
    print("Warning: markdown_pdf module not available. PDF conversion will be disabled.")

try:
    import pty
    HAS_PTY = True
except Exception:
    HAS_PTY = False

# Pydantic ëª¨ë¸ ì •ì˜
class TerraformContent(BaseModel):
    module_code: str

class ReadOnlyCliRequest(BaseModel):
    provider: str
    command_name: str
    args: Optional[dict] = {}

class ReadOnlyCliResponse(BaseModel):
    success: bool
    stdout: Optional[str] = None
    stderr: Optional[str] = None

class GeminiReviewResponse(BaseModel):
    summary: str
    issues: List[str] = []

class DeploymentRequest(BaseModel):
    name: str
    cloud: str
    module: str
    vars: dict

class DeploymentResponse(BaseModel):
    id: int
    name: str
    cloud: str
    module: str
    vars: dict
    status: DeploymentStatus
    created_at: datetime
    updated_at: datetime
    terraform_plan_output: Optional[str] = None
    terraform_apply_log: Optional[str] = None
    gemini_review_summary: Optional[str] = None
    gemini_review_issues: Optional[List[str]] = None

class DataSourceRequest(BaseModel):
    provider: str
    data_type: str
    data_name: str
    config: dict

class DataSourceResponse(BaseModel):
    success: bool
    output: Optional[dict] = None
    error: Optional[str] = None
    
    class Config:
        from_attributes = True

# DataSource CRUDë¥¼ ìœ„í•œ Pydantic ëª¨ë¸ë“¤
class DataSourceCreate(BaseModel):
    name: str
    provider: str
    data_type: str
    config: dict

class DataSourceUpdate(BaseModel):
    name: Optional[str] = None
    provider: Optional[str] = None
    data_type: Optional[str] = None
    config: Optional[dict] = None

class DataSourceInDB(BaseModel):
    id: int
    name: str
    provider: str
    data_type: str
    config: dict
    created_at: datetime
    updated_at: datetime
    
    class Config:
        from_attributes = True

# AI Assistantë¥¼ ìœ„í•œ Pydantic ëª¨ë¸
class AgentQueryRequest(BaseModel):
    query: str

# ì§€ì‹ë² ì´ìŠ¤ë¥¼ ìœ„í•œ ëª¨ë¸
class DocumentContentRequest(BaseModel):
    path: str

# Markdown to PDF conversion request
class MarkdownToPdfRequest(BaseModel):
    markdown: str
    filename: Optional[str] = "document.md"

# ë°ì´í„°ë² ì´ìŠ¤ URL í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸° (Docker í™˜ê²½ ìš°ì„ )
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://mcpuser:mcppassword@mcp_postgres:5432/mcp_db")
print(f"ğŸ”— Database URL: {DATABASE_URL}")

# Gemini API Key í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "dummy_key")

# API Key for authentication
MCP_API_KEY = os.getenv("MCP_API_KEY", "my_mcp_eagle_tiger")

api_key_header = APIKeyHeader(name="X-API-Key", auto_error=False)

async def get_api_key(request: Request):
    # Accept API key via header or `api_key` query parameter
    provided = request.headers.get("x-api-key") or request.query_params.get("api_key")
    # Read current expected key dynamically to respect test-time env overrides
    expected = os.getenv("MCP_API_KEY", MCP_API_KEY)
    if provided == expected:
        return provided
    raise HTTPException(status_code=403, detail="Could not validate credentials")

# SQLAlchemy ì—”ì§„ ìƒì„± (ì—ëŸ¬ ì²˜ë¦¬ ì¶”ê°€)
try:
    engine = create_engine(DATABASE_URL, echo=False)
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ (SQLAlchemy 2.0 í˜¸í™˜)
    from sqlalchemy import text
    with engine.connect() as conn:
        conn.execute(text("SELECT 1"))
        print("Database connection successful!")
        
except Exception as e:
    print(f"Database connection failed: {e}")
    print("Using in-memory database for now...")
    # SQLite ì¸ë©”ëª¨ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ë¡œ í´ë°±
    engine = create_engine("sqlite:///:memory:", echo=False)
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± (ì—ëŸ¬ ì²˜ë¦¬ ì¶”ê°€)
try:
    Base.metadata.create_all(bind=engine)
    print("Database tables created successfully!")
except Exception as e:
    print(f"Failed to create database tables: {e}")

app = FastAPI()

# CORS Middleware
origins = [
    "http://localhost",
    "http://localhost:3000", # React frontend origin
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===================================
# Constants & Helper Functions
# ===================================
KNOWLEDGE_BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'mcp_knowledge_base'))

def get_knowledge_base_structure(path, is_root: bool = False):
    """ Recursively builds a dictionary representing the directory structure.
    - Directories are ordered alphabetically with 'appendix' placed last.
    - Markdown files are listed under the special key 'files' and sorted alphabetically.
    """
    structure: dict = {}

    directories: List[str] = []
    markdown_files: List[str] = []

    for item in os.listdir(path):
        item_path = os.path.join(path, item)
        if os.path.isdir(item_path):
            directories.append(item)
        elif item.endswith('.md'):
            # Exclude Curriculum.md from the root textbook listing
            if is_root and item.lower() == 'curriculum.md':
                continue
            markdown_files.append(item)

    # Order directories with 'appendix' always at the end (case-insensitive)
    directories.sort(key=lambda name: (name.lower() == 'appendix', name.lower()))

    for directory_name in directories:
        structure[directory_name] = get_knowledge_base_structure(os.path.join(path, directory_name), is_root=False)

    if markdown_files:
        markdown_files.sort()
        structure['files'] = markdown_files

    return structure

# ===================================

# ===================================
# DataSource CRUD Endpoints
# ===================================

@app.post("/api/v1/datasources/", response_model=DataSourceInDB, dependencies=[Depends(get_api_key)])
def create_data_source(datasource: DataSourceCreate, db: Session = Depends(get_db)):
    db_datasource = db.query(DataSource).filter(DataSource.name == datasource.name).first()
    if db_datasource:
        raise HTTPException(status_code=400, detail="DataSource with this name already exists")
    new_datasource = DataSource(**datasource.dict())
    db.add(new_datasource)
    db.commit()
    db.refresh(new_datasource)
    return new_datasource

@app.get("/api/v1/datasources/", response_model=List[DataSourceInDB], dependencies=[Depends(get_api_key)])
def list_data_sources(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    datasources = db.query(DataSource).offset(skip).limit(limit).all()
    return datasources

@app.get("/api/v1/datasources/{datasource_id}", response_model=DataSourceInDB, dependencies=[Depends(get_api_key)])
def get_data_source(datasource_id: int, db: Session = Depends(get_db)):
    db_datasource = db.query(DataSource).filter(DataSource.id == datasource_id).first()
    if db_datasource is None:
        raise HTTPException(status_code=404, detail="DataSource not found")
    return db_datasource

@app.put("/api/v1/datasources/{datasource_id}", response_model=DataSourceInDB, dependencies=[Depends(get_api_key)])
def update_data_source(datasource_id: int, datasource: DataSourceUpdate, db: Session = Depends(get_db)):
    db_datasource = db.query(DataSource).filter(DataSource.id == datasource_id).first()
    if db_datasource is None:
        raise HTTPException(status_code=404, detail="DataSource not found")
    
    for key, value in datasource.dict().items():
        setattr(db_datasource, key, value)
    
    db.commit()
    db.refresh(db_datasource)
    return db_datasource

@app.delete("/api/v1/datasources/{datasource_id}", response_model=DataSourceInDB, dependencies=[Depends(get_api_key)])
def delete_data_source(datasource_id: int, db: Session = Depends(get_db)):
    db_datasource = db.query(DataSource).filter(DataSource.id == datasource_id).first()
    if db_datasource is None:
        raise HTTPException(status_code=404, detail="DataSource not found")
    db.delete(db_datasource)
    db.commit()
    return db_datasource

# ===================================

# Gemini API ì„¤ì •
genai.configure(api_key=GEMINI_API_KEY)

def run_terraform_command(command: List[str], working_dir: str):
    """
    ì§€ì •ëœ ë””ë ‰í„°ë¦¬ì—ì„œ Terraform ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    try:
        result = subprocess.run(
            command,
            cwd=working_dir,
            capture_output=True,
            text=True,
            check=True
        )
        return result.stdout
    except subprocess.CalledProcessError as e:
        # Re-raise the exception to be handled by the caller
        raise e
    except FileNotFoundError:
        raise HTTPException(status_code=500, detail="Terraform ì‹¤í–‰ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

@app.get("/")
def read_root():
    return {"message": "MCP Backend is running!"}

@app.get("/health")
def health_check():
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.post("/api/v1/agent/query", dependencies=[Depends(get_api_key)])
async def agent_query(request: AgentQueryRequest):
    """
    ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë°›ì•„ RAG ì²´ì¸ì„ í†µí•´ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not rag_service_instance:
        raise HTTPException(status_code=503, detail="RAG service is not available.")
    
    try:
        return StreamingResponse(
            rag_service_instance.query_stream(request.query), 
            media_type="text/event-stream"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"An error occurred in the RAG service: {e}")

@app.get("/api/v1/knowledge-base/tree", dependencies=[Depends(get_api_key)])
async def get_knowledge_base_tree():
    """
    ì§€ì‹ ë² ì´ìŠ¤ì˜ ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ JSON í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        tree = get_knowledge_base_structure(KNOWLEDGE_BASE_DIR)
        return tree
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to read knowledge base structure: {e}")

@app.post("/api/v1/knowledge-base/content", dependencies=[Depends(get_api_key)])
async def get_document_content(request: DocumentContentRequest):
    """
    ìš”ì²­ëœ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì˜ ë‚´ìš©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    ë³´ì•ˆì„ ìœ„í•´ íŒŒì¼ ê²½ë¡œëŠ” mcp_knowledge_base ë‚´ë¡œ ì œí•œë©ë‹ˆë‹¤.
    """
    try:
        # Sanitize the requested path to prevent directory traversal
        # os.path.join will handle the slashes correctly for the OS
        relative_path = os.path.normpath(request.path.strip(r'./\ ')) # Corrected escape sequence here
        secure_path = os.path.join(KNOWLEDGE_BASE_DIR, relative_path)

        # Security Check: Ensure the final path is within the knowledge base directory
        if not os.path.commonpath([KNOWLEDGE_BASE_DIR]) == os.path.commonpath([KNOWLEDGE_BASE_DIR, secure_path]):
            raise HTTPException(status_code=400, detail="Invalid or malicious file path.")

        if not os.path.exists(secure_path) or not secure_path.endswith('.md'):
            raise HTTPException(status_code=404, detail="File not found or not a markdown file.")

        with open(secure_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return {"path": relative_path, "content": content}

    except HTTPException as e:
        # Re-raise HTTP exceptions to let FastAPI handle them
        raise e
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to read document content: {e}")


# ===================================
# Curriculum Endpoints
# ===================================
TEXTBOOK_DIR = os.path.join(KNOWLEDGE_BASE_DIR, 'textbook')
SLIDES_DIR = os.path.join(KNOWLEDGE_BASE_DIR, 'slides')

@app.get("/api/v1/curriculum/tree", dependencies=[Depends(get_api_key)])
async def get_curriculum_tree():
    """
    Returns the directory structure of the textbook as JSON.
    """
    try:
        # We can reuse the existing helper function
        tree = get_knowledge_base_structure(TEXTBOOK_DIR, is_root=True)
        return tree
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to read curriculum structure: {e}")

@app.get("/api/v1/curriculum/content", dependencies=[Depends(get_api_key)])
async def get_curriculum_content(path: str):
    """
    Returns the content of a requested markdown file from the textbook directory.
    """
    try:
        # Sanitize path
        relative_path = os.path.normpath(path.strip(r'./\ ')) # Corrected escape sequence here
        secure_path = os.path.join(TEXTBOOK_DIR, relative_path)

        if not os.path.commonpath([TEXTBOOK_DIR]) == os.path.commonpath([TEXTBOOK_DIR, secure_path]):
            raise HTTPException(status_code=400, detail="Invalid file path.")

        if not os.path.exists(secure_path) or not secure_path.endswith('.md'):
            raise HTTPException(status_code=404, detail="File not found or not a markdown file.")

        with open(secure_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return {"path": relative_path, "content": content}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to read content: {e}")

@app.get("/api/v1/curriculum/slide")
async def get_slide_download(textbook_path: str, request: Request):
    # Allow api key via header or query param for downloads (avoids CORS preflight issues)
    await get_api_key(request)
    """
    Finds the corresponding slide for a textbook path and returns it for download.
    For now, it returns the markdown content. PDF conversion can be added later.
    """
    try:
        # Prefer exact basename match, e.g., textbook/part1/day1/1-2_account_setup.md -> slides/1-2_account_setup.md
        basename = os.path.basename(textbook_path)
        found_slide = None
        if basename in os.listdir(SLIDES_DIR):
            found_slide = basename
        else:
            # Fallback: textbook/part1/day1/intro.md -> slides/1-1_intro.md
            parts = textbook_path.split(os.path.sep)
            if len(parts) >= 3 and parts[0].startswith('part'):
                part_num = parts[0].replace('part', '')
                day_num = parts[1].replace('day', '')
                topic = os.path.splitext(parts[-1])[0]
                slide_prefix = f"{part_num}-{day_num}_"
                for filename in os.listdir(SLIDES_DIR):
                    if filename.startswith(slide_prefix) and topic in filename:
                        found_slide = filename
                        break
        
        if not found_slide:
            raise HTTPException(status_code=404, detail="Slide mapping is not defined for this document.")

        slide_path = os.path.join(SLIDES_DIR, found_slide)
        # Try Marp PDF conversion if available; fallback to raw markdown
        import shutil, subprocess, tempfile
        marp_bin = shutil.which("marp")
        if marp_bin:
            with tempfile.TemporaryDirectory() as tmpdir:
                pdf_out = os.path.join(tmpdir, os.path.splitext(found_slide)[0] + ".pdf")
                try:
                    # Optional browser path for puppeteer (Windows/enterprise env)
                    browser_path = os.getenv("MARP_BROWSER_PATH")
                    cmd = [
                        marp_bin,
                        slide_path,
                        "--pdf",
                        "--allow-local-files",
                        "--timeout",
                        os.getenv("MARP_TIMEOUT_MS", "120000"),
                        "-o",
                        pdf_out,
                    ]
                    if browser_path:
                        cmd.extend(["--browser", browser_path])
                    # Allow setting PUPPETEER_EXECUTABLE_PATH via env
                    env = os.environ.copy()
                    if os.getenv("PUPPETEER_EXECUTABLE_PATH"):
                        env["PUPPETEER_EXECUTABLE_PATH"] = os.getenv("PUPPETEER_EXECUTABLE_PATH")
                    subprocess.run(
                        cmd,
                        check=True,
                        capture_output=True,
                        text=True,
                        env=env,
                    )
                    return FileResponse(
                        pdf_out,
                        media_type="application/pdf",
                        filename=os.path.basename(pdf_out),
                    )
                except subprocess.CalledProcessError:
                    pass
        # No marp available or conversion failed: return markdown
        return FileResponse(
            slide_path,
            media_type="text/markdown; charset=utf-8",
            filename=found_slide,
        )

    except HTTPException as e:
        raise e
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get slide: {e}")

# Generic Markdown -> PDF conversion using Marp (if available)
@app.post("/api/v1/markdown/pdf", dependencies=[Depends(get_api_key)])
async def convert_markdown_to_pdf(req: MarkdownToPdfRequest):
    try:
        import shutil, tempfile, subprocess, os as _os
        marp_bin = shutil.which("marp")
        # Write markdown to temp file
        with tempfile.TemporaryDirectory() as tmpdir:
            md_path = _os.path.join(tmpdir, req.filename or "document.md")
            with open(md_path, "w", encoding="utf-8") as f:
                f.write(req.markdown)
            if marp_bin:
                pdf_out = _os.path.join(tmpdir, _os.path.splitext(_os.path.basename(md_path))[0] + ".pdf")
                try:
                    subprocess.run([marp_bin, md_path, "--pdf", "--allow-local-files", "-o", pdf_out],
                                   check=True, capture_output=True, text=True)
                    return FileResponse(pdf_out, media_type="application/pdf",
                                         filename=_os.path.basename(pdf_out))
                except subprocess.CalledProcessError as e:
                    raise HTTPException(status_code=500, detail=f"Marp conversion failed: {e.stderr or e.stdout}")
            # Fallback: return markdown if Marp not available
            return FileResponse(md_path, media_type="text/markdown; charset=utf-8",
                                 filename=_os.path.basename(md_path))
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to convert markdown: {e}")

@app.get("/api/v1/slides/{slide_name}/pdf", dependencies=[Depends(get_api_key)])
async def get_slide_pdf(slide_name: str):
    """
    Converts a specified slide markdown file to PDF and returns it.
    """
    try:
        # Sanitize the slide_name to prevent directory traversal
        # Use os.path.abspath to get the absolute path, then check if it's within SLIDES_DIR
        requested_path = os.path.join(SLIDES_DIR, slide_name.strip(r'./\ '))
        
        # Ensure the file is a markdown file
        if not requested_path.endswith('.md'):
            requested_path += '.md'

        # Resolve the real path to handle '..' and symlinks
        real_path = os.path.realpath(requested_path)

        # Security Check: Ensure the real path is within the SLIDES_DIR
        if not real_path.startswith(os.path.realpath(SLIDES_DIR)):
            raise HTTPException(status_code=400, detail="Invalid or malicious slide name.")

        slide_path = real_path # Use the real_path for opening the file

        if not os.path.exists(slide_path):
            raise HTTPException(status_code=404, detail="Slide not found.")

        # Read markdown content
        with open(slide_path, 'r', encoding='utf-8') as f:
            markdown_content = f.read()

        # Convert markdown to PDF
        if not HAS_MARKDOWN_PDF:
            # Fallback: return markdown content as text
            return StreamingResponse(
                iter([markdown_content]),
                media_type="text/markdown",
                headers={'Content-Disposition': f'attachment; filename="{os.path.splitext(slide_name)[0]}.md"'}
            )
            
        # Use MarkdownPdf if available
        pdf = MarkdownPdf()
        pdf.add_section(Section(markdown_content, toc=False))
        
        # Save PDF to a BytesIO object
        buffer = BytesIO()
        pdf.save(buffer)
        buffer.seek(0) # Rewind to the beginning of the buffer

        return StreamingResponse(
            buffer,
            media_type="application/pdf",
            headers={'Content-Disposition': f'attachment; filename="{os.path.splitext(slide_name)[0]}.pdf"'}
        )

    except HTTPException as e:
        raise e
    except Exception as e:
        print(f"Error during PDF conversion: {e}") # Added for debugging
        raise HTTPException(status_code=500, detail=f"Failed to convert slide to PDF: {e}")




@app.post("/deployments/", response_model=DeploymentResponse, dependencies=[Depends(get_api_key)])
def create_deployment(request: DeploymentRequest, db: Session = Depends(get_db)):
    new_deployment = Deployment(
        name=request.name,
        cloud=request.cloud,
        module=request.module,
        vars=request.vars,
        status=DeploymentStatus.CREATED
    )
    db.add(new_deployment)
    db.commit()
    db.refresh(new_deployment)
    return new_deployment

@app.get("/deployments/{deployment_id}", response_model=DeploymentResponse)
def get_deployment(deployment_id: int, db: Session = Depends(get_db)):
    deployment = db.query(Deployment).filter(Deployment.id == deployment_id).first()
    if not deployment:
        raise HTTPException(status_code=404, detail="Deployment not found")
    return deployment

@app.post("/deployments/{deployment_id}/review_with_gemini", response_model=GeminiReviewResponse, dependencies=[Depends(get_api_key)])
async def review_terraform_with_gemini(deployment_id: int, content: TerraformContent, db: Session = Depends(get_db)):
    deployment = db.query(Deployment).filter(Deployment.id == deployment_id).first()
    if not deployment:
        raise HTTPException(status_code=404, detail="Deployment not found")
        
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        prompt = f"""
        ë‹¤ìŒ Terraform ëª¨ë“ˆ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³ , ìœ íš¨ì„± ê²€ì¦ ë° ë³´ì•ˆ ì·¨ì•½ì ì„ ê²€í† í•´ì¤˜.
        1. HCL(HashiCorp Configuration Language) ë¬¸ë²• ì˜¤ë¥˜ê°€ ì—†ëŠ”ì§€ í™•ì¸í•´ì¤˜.
        2. ë³€ìˆ˜(variables)ì™€ ì¶œë ¥(outputs)ì´ ëª…í™•í•˜ê²Œ ì •ì˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì¤˜.
        3. ì¼ë°˜ì ì¸ ë³´ì•ˆ ì·¨ì•½ì (ì˜ˆ: í•˜ë“œì½”ë”©ëœ ë¹„ë°€ë²ˆí˜¸)ì´ ì—†ëŠ”ì§€ í™•ì¸í•´ì¤˜.
        4. ëª¨ë“ˆì˜ ëª©ì ê³¼ ê¸°ëŠ¥ì„ 100ì ë‚´ì™¸ë¡œ ìš”ì•½í•´ì¤˜. 
        
        ì‘ë‹µì€ ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ í•´ì¤˜:
        {{
            "summary": "ëª¨ë“ˆì— ëŒ€í•œ ìš”ì•½",
            "issues": ["ì´ìŠˆ 1", "ì´ìŠˆ 2", "..."]
        }}

        ---
        Terraform Code:
        {content.module_code}
        ---
        """
        
        response = await model.generate_content_async(
            prompt,
            generation_config=genai.types.GenerationConfig(
                response_mime_type="application/json"
            )
        )
        
        gemini_result = json.loads(response.text)
        
        deployment.gemini_review_summary = gemini_result.get("summary")
        deployment.gemini_review_issues = gemini_result.get("issues")
        db.commit()
        db.refresh(deployment)
        
        return GeminiReviewResponse(**gemini_result)
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"An unexpected error occurred: {e}")

READ_ONLY_COMMAND_WHITELIST = {
    "aws": {
        # existing
        "get-caller-identity": ["aws", "sts", "get-caller-identity"],
        # frontend expects these
        "s3_ls": ["aws", "s3", "ls"],
        "ec2_describe_instances": ["aws", "ec2", "describe-instances"],
        "iam_list_users": ["aws", "iam", "list-users"],
        "vpc_describe_vpcs": ["aws", "ec2", "describe-vpcs"],
    },
    "gcp": {
        # existing
        "auth-list": ["gcloud", "auth", "list"],
        # frontend expects these
        "gcloud_zones_list": ["gcloud", "compute", "zones", "list"],
        "gcloud_projects_list": ["gcloud", "projects", "list"],
        "gcloud_storage_buckets_list": ["gcloud", "storage", "buckets", "list"],
        "gcloud_compute_instances_list": ["gcloud", "compute", "instances", "list"],
    }
}

@app.post("/cli/read-only", response_model=ReadOnlyCliResponse, dependencies=[Depends(get_api_key)])
def run_readonly_cli_command(request: ReadOnlyCliRequest):
    """
    Executes a whitelisted, read-only CLI command for AWS or GCP.
    """
    provider_commands = READ_ONLY_COMMAND_WHITELIST.get(request.provider)
    if not provider_commands:
        raise HTTPException(status_code=400, detail=f"Provider '{request.provider}' is not supported.")

    command_template = provider_commands.get(request.command_name)
    if not command_template:
        raise HTTPException(status_code=400, detail=f"Command '{request.command_name}' is not a valid or allowed read-only command.")

    # Basic argument handling (more sophisticated validation can be added)
    command = command_template.copy()
    if request.args:
        for key, value in request.args.items():
            command.append(f"--{key}")
            command.append(str(value))

    try:
        result = subprocess.run(
            command,
            capture_output=True,
            text=True,
            check=False # We handle the return code manually
        )
        
        success = result.returncode == 0
        return ReadOnlyCliResponse(
            success=success,
            stdout=result.stdout.strip(),
            stderr=result.stderr.strip()
        )

    except FileNotFoundError:
        raise HTTPException(status_code=500, detail=f"Could not find the command for provider '{request.provider}'. Is the CLI installed?")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"An unexpected error occurred: {e}")

# Backward-compatible API under versioned prefix
@app.post("/api/v1/cli/read-only", response_model=ReadOnlyCliResponse, dependencies=[Depends(get_api_key)])
def run_readonly_cli_command_v1(request: ReadOnlyCliRequest):
    return run_readonly_cli_command(request)

@app.post("/deployments/{deployment_id}/plan", response_model=DeploymentResponse, dependencies=[Depends(get_api_key)])
def run_plan(deployment_id: int, db: Session = Depends(get_db)):
    deployment = db.query(Deployment).filter(Deployment.id == deployment_id).first()
    if not deployment:
        raise HTTPException(status_code=404, detail="Deployment not found")
        
    if deployment.status not in [DeploymentStatus.CREATED, DeploymentStatus.FAILED]:
        raise HTTPException(status_code=400, detail=f"Cannot run plan for deployment with status: {deployment.status}")

    # Note: This path needs to be flexible for local vs. container execution.
    # For now, we assume a 'terraform_modules' directory exists at the project root.
    module_path = os.path.join("terraform_modules", deployment.module)
    if not os.path.isdir(module_path):
        raise HTTPException(status_code=404, detail=f"Terraform module not found at: {module_path}")

    try:
        plan_output = run_terraform_command(
            ["terraform", "plan"], # Simplified for now, vars handling needed
            working_dir=module_path
        )
        deployment.status = DeploymentStatus.PLANNED
    except subprocess.CalledProcessError as e:
        plan_output = e.stderr
        deployment.status = DeploymentStatus.FAILED

    deployment.terraform_plan_output = plan_output
    
    db.commit()
    db.refresh(deployment)
    
    return deployment

@app.post("/deployments/{deployment_id}/apply", response_model=DeploymentResponse, dependencies=[Depends(get_api_key)])
def run_apply(deployment_id: int, db: Session = Depends(get_db)):
    deployment = db.query(Deployment).filter(Deployment.id == deployment_id).first()
    if not deployment:
        raise HTTPException(status_code=404, detail="Deployment not found")

    if deployment.status != DeploymentStatus.PLANNED:
        raise HTTPException(status_code=400, detail=f"Cannot run apply for deployment with status: {deployment.status}")

    module_path = os.path.join("terraform_modules", deployment.module)
    
    try:
        apply_log = run_terraform_command(
            ["terraform", "apply", "-auto-approve"], # Simplified
            working_dir=module_path
        )
        deployment.status = DeploymentStatus.APPLIED
    except subprocess.CalledProcessError as e:
        apply_log = e.stderr
        deployment.status = DeploymentStatus.FAILED
    
    deployment.terraform_apply_log = apply_log
    
    db.commit()
    db.refresh(deployment)
    
    return deployment

@app.post("/deployments/{deployment_id}/approve", response_model=DeploymentResponse, dependencies=[Depends(get_api_key)])
def approve_deployment(deployment_id: int, db: Session = Depends(get_db)):
    deployment = db.query(Deployment).filter(Deployment.id == deployment_id).first()
    if not deployment:
        raise HTTPException(status_code=404, detail="Deployment not found")
        
    if deployment.status != DeploymentStatus.PLANNED:
        raise HTTPException(status_code=400, detail=f"Cannot approve deployment with status: {deployment.status}")
        
    deployment.status = DeploymentStatus.AWAITING_APPROVAL
    db.commit()
    db.refresh(deployment)
    
    return deployment

@app.post("/api/v1/data-sources/query", response_model=DataSourceResponse, dependencies=[Depends(get_api_key)])
def query_data_source(request: DataSourceRequest):
    temp_dir = tempfile.mkdtemp()
    try:
        # HCL ìƒì„± (ì•ˆì „í•œ ë¬¸ìì—´ ì¡°í•©)
        lines: List[str] = []
        lines.append("terraform {")
        lines.append("  required_providers {")
        lines.append(f"    {request.provider} = {{")
        lines.append(f"      source = \"hashicorp/{request.provider}\"")
        lines.append("    }")
        lines.append("  }")
        lines.append("}")
        lines.append("")
        lines.append(f"provider \"{request.provider}\" {{}}")
        lines.append("")
        lines.append(f"data \"{request.data_type}\" \"{request.data_name}\" {{")
        for k, v in request.config.items():
            if isinstance(v, str):
                lines.append(f"  {k} = \"{v}\"")
            else:
                lines.append(f"  {k} = {json.dumps(v)}")
        lines.append("}")
        lines.append("")
        lines.append("output \"result\" {")
        lines.append(f"  value = data.{request.data_type}.{request.data_name}")
        lines.append("  sensitive = true")
        lines.append("}")
        hcl_config = "\n".join(lines)

        tf_file_path = os.path.join(temp_dir, "main.tf")
        with open(tf_file_path, "w", encoding="utf-8") as f:
            f.write(hcl_config)

        # Terraform init & apply (non-JSON). Use separate 'terraform output -json' for outputs
        run_terraform_command(["terraform", "init", "-input=false"], temp_dir)
        run_terraform_command(["terraform", "apply", "-auto-approve", "-input=false"], temp_dir)

        # ê²°ê³¼ íŒŒì‹±: 'terraform output -json'ì—ì„œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
        try:
            outputs_raw = run_terraform_command(["terraform", "output", "-json"], temp_dir)
            output_json = json.loads(outputs_raw)
            result = output_json.get("result", {}).get("value")
        except Exception as parse_err:
            return DataSourceResponse(success=False, error=f"Failed to parse terraform outputs: {parse_err}")

        return DataSourceResponse(success=True, output=result)

    except subprocess.CalledProcessError as e:
        err_text = e.stderr if e.stderr else (e.stdout if e.stdout else "Terraform command failed without stderr/stdout.")
        return DataSourceResponse(success=False, error=err_text)
    except Exception as e:
        print(f"Error in query_data_source: {e}") # Debug print
        return DataSourceResponse(success=False, error=str(e))
    finally:
        shutil.rmtree(temp_dir)

# Backward-compatible API without versioned prefix
@app.post("/data-sources/query", response_model=DataSourceResponse, dependencies=[Depends(get_api_key)])
def query_data_source_legacy(request: DataSourceRequest):
    return query_data_source(request)

# AI Agent ê³ ë„í™” ê¸°ëŠ¥ì„ ìœ„í•œ ìƒˆë¡œìš´ API ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.post("/ai/terraform/generate", dependencies=[Depends(get_api_key)])
async def generate_terraform_code(request: dict):
    """ìì—°ì–´ ìš”êµ¬ì‚¬í•­ì„ ë°”íƒ•ìœ¼ë¡œ Terraform ì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        requirements = request.get("requirements", "")
        cloud_provider = request.get("cloud_provider", "aws")
        
        if not requirements:
            raise HTTPException(status_code=400, detail="ìš”êµ¬ì‚¬í•­ì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        if cloud_provider not in ["aws", "gcp"]:
            raise HTTPException(status_code=400, detail="ì§€ì›ë˜ëŠ” í´ë¼ìš°ë“œ ì œê³µì: aws, gcp")
        
        result = rag_service_instance.generate_terraform_code(requirements, cloud_provider)
        return {"success": True, "result": result}
    
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/ai/terraform/validate", dependencies=[Depends(get_api_key)])
async def validate_terraform_code(request: dict):
    """Terraform ì½”ë“œì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤."""
    try:
        terraform_code = request.get("terraform_code", "")
        
        if not terraform_code:
            raise HTTPException(status_code=400, detail="Terraform ì½”ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        result = rag_service_instance.validate_terraform_code(terraform_code)
        return {"success": True, "result": result}
    
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/ai/cost/analyze", dependencies=[Depends(get_api_key)])
async def analyze_infrastructure_cost(request: dict):
    """ì¸í”„ë¼ ì„¤ëª…ì„ ë°”íƒ•ìœ¼ë¡œ ë¹„ìš© ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    try:
        infrastructure_description = request.get("infrastructure_description", "")
        cloud_provider = request.get("cloud_provider", "aws")
        
        if not infrastructure_description:
            raise HTTPException(status_code=400, detail="ì¸í”„ë¼ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        if cloud_provider not in ["aws", "gcp"]:
            raise HTTPException(status_code=400, detail="ì§€ì›ë˜ëŠ” í´ë¼ìš°ë“œ ì œê³µì: aws, gcp")
        
        result = rag_service_instance.analyze_cost(infrastructure_description, cloud_provider)
        return {"success": True, "result": result}
    
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/ai/security/audit", dependencies=[Depends(get_api_key)])
async def audit_infrastructure_security(request: dict):
    """ì¸í”„ë¼ ì„¤ëª…ì„ ë°”íƒ•ìœ¼ë¡œ ë³´ì•ˆ ê°ì‚¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    try:
        infrastructure_description = request.get("infrastructure_description", "")
        cloud_provider = request.get("cloud_provider", "aws")
        
        if not infrastructure_description:
            raise HTTPException(status_code=400, detail="ì¸í”„ë¼ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        if cloud_provider not in ["aws", "gcp"]:
            raise HTTPException(status_code=400, detail="ì§€ì›ë˜ëŠ” í´ë¼ìš°ë“œ ì œê³µì: aws, gcp")
        
        result = rag_service_instance.audit_security(infrastructure_description, cloud_provider)
        return {"success": True, "result": result}
    
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/ai/assistant/query", dependencies=[Depends(get_api_key)])
async def query_ai_assistant(request: dict):
    """AI ì–´ì‹œìŠ¤í„´íŠ¸ì—ê²Œ ì§ˆë¬¸í•˜ê³  ë‹µë³€ì„ ë°›ìŠµë‹ˆë‹¤."""
    try:
        question = request.get("question", "")
        
        if not question:
            raise HTTPException(status_code=400, detail="ì§ˆë¬¸ì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìœ„í•œ ì œë„ˆë ˆì´í„°
        async def generate_response():
            async for chunk in rag_service_instance.query_stream(question):
                yield f"data: {json.dumps({'chunk': chunk}, ensure_ascii=False)}\n\n"
        
        return StreamingResponse(generate_response(), media_type="text/plain")
    
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/ai/assistant/query-sync", dependencies=[Depends(get_api_key)])
async def query_ai_assistant_sync(request: dict):
    """AI ì–´ì‹œìŠ¤í„´íŠ¸ì—ê²Œ ì§ˆë¬¸í•˜ê³  ë™ê¸°ì ìœ¼ë¡œ ë‹µë³€ì„ ë°›ìŠµë‹ˆë‹¤."""
    try:
        question = request.get("question", "")
        
        if not question:
            raise HTTPException(status_code=400, detail="ì§ˆë¬¸ì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        answer = rag_service_instance.query(question)
        return {"success": True, "answer": answer}
    
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/ai/knowledge/search", dependencies=[Depends(get_api_key)])
async def search_knowledge_base(query: str, limit: int = 3):
    """ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    try:
        if not query:
            raise HTTPException(status_code=400, detail="ê²€ìƒ‰ ì¿¼ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        documents = rag_service_instance.get_similar_documents(query, limit)
        
        # Document ê°ì²´ë¥¼ ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        serialized_docs = []
        for doc in documents:
            serialized_docs.append({
                "content": doc.page_content,
                "metadata": doc.metadata
            })
        
        return {"success": True, "documents": serialized_docs}
    
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/ai/knowledge/update", dependencies=[Depends(get_api_key)])
async def update_knowledge_base():
    """ì§€ì‹ë² ì´ìŠ¤ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    try:
        success = rag_service_instance.update_knowledge_base()
        if success:
            return {"success": True, "message": "ì§€ì‹ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤"}
        else:
            return {"success": False, "error": "ì§€ì‹ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"}
    
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/ai/infrastructure/recommend", dependencies=[Depends(get_api_key)])
async def get_infrastructure_recommendations(request: dict):
    """ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ ì¸í”„ë¼ ì•„í‚¤í…ì²˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤."""
    try:
        requirements = request.get("requirements", "")
        cloud_provider = request.get("cloud_provider", "aws")
        budget_constraint = request.get("budget_constraint", "")
        security_requirements = request.get("security_requirements", "")
        
        if not requirements:
            raise HTTPException(status_code=400, detail="ìš”êµ¬ì‚¬í•­ì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ì¢…í•©ì ì¸ ì¸í”„ë¼ ì¶”ì²œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
        ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ {cloud_provider} í´ë¼ìš°ë“œ ì¸í”„ë¼ ì•„í‚¤í…ì²˜ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”:
        
        ìš”êµ¬ì‚¬í•­: {requirements}
        ì˜ˆì‚° ì œì•½: {budget_constraint if budget_constraint else 'ì œí•œ ì—†ìŒ'}
        ë³´ì•ˆ ìš”êµ¬ì‚¬í•­: {security_requirements if security_requirements else 'ê¸°ë³¸ ë³´ì•ˆ'}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µì„ ì œê³µí•´ì£¼ì„¸ìš”:
        {{
            "architecture_overview": "ì „ì²´ ì•„í‚¤í…ì²˜ ê°œìš”",
            "recommended_services": ["ì¶”ì²œ ì„œë¹„ìŠ¤ ëª©ë¡"],
            "estimated_monthly_cost": "ì˜ˆìƒ ì›” ë¹„ìš©",
            "security_features": ["ë³´ì•ˆ ê¸°ëŠ¥"],
            "scalability_features": ["í™•ì¥ì„± ê¸°ëŠ¥"],
            "terraform_modules": ["í•„ìš”í•œ Terraform ëª¨ë“ˆ"],
            "deployment_steps": ["ë°°í¬ ë‹¨ê³„"],
            "best_practices": ["ëª¨ë²” ì‚¬ë¡€"],
            "risk_mitigation": ["ìœ„í—˜ ì™„í™” ë°©ì•ˆ"]
        }}
        """
        
        # Gemini APIë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ ì¶”ì²œ ìƒì„±
        import google.generativeai as genai
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-pro')
        
        response = model.generate_content(prompt)
        
        try:
            # JSON ì‘ë‹µì„ íŒŒì‹±
            import re
            json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                return {"success": True, "recommendations": result}
            else:
                return {"success": True, "recommendations": {"raw_response": response.text}}
        except json.JSONDecodeError:
            return {"success": True, "recommendations": {"raw_response": response.text}}
    
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.websocket("/ws/v1/cli/interactive")
async def websocket_interactive_cli(websocket: WebSocket):
    await websocket.accept()
    
    # ì²« ë²ˆì§¸ ë©”ì‹œì§€ì—ì„œ API í‚¤ ì¸ì¦ ì²˜ë¦¬
    try:
        auth_message = await websocket.receive_text()
        auth_data = json.loads(auth_message)
        
        if auth_data.get('type') == 'auth':
            provided_key = auth_data.get('api_key')
            expected_key = os.getenv("MCP_API_KEY", MCP_API_KEY)
            
            if provided_key != expected_key:
                await websocket.send_text("Authentication failed. Invalid API key.")
                await websocket.close()
                return
        else:
            await websocket.send_text("Authentication required. Please provide API key.")
            await websocket.close()
            return
    except (json.JSONDecodeError, KeyError):
        await websocket.send_text("Invalid authentication message format.")
        await websocket.close()
        return
    
    if not HAS_PTY:
        await websocket.send_text("Interactive shell is not supported on this platform.")
        await websocket.close()
        return
    
    # This is a simplified implementation using a local pty.
    # For enhanced security, this should be executed inside a Docker container.
    master_fd, slave_fd = pty.openpty()
    
    # Start a shell process
    shell_process = await asyncio.create_subprocess_shell(
        'sh',
        stdin=slave_fd,
        stdout=slave_fd,
        stderr=slave_fd,
        close_fds=True
    )

    # Task to forward output from shell to websocket
    async def forward_output():
        import select
        while True:
            r, _, _ = select.select([master_fd], [], [], 0)
            if r:
                try:
                    output = os.read(master_fd, 1024)
                    if output:
                        await websocket.send_text(output.decode())
                    else:
                        break # EOF
                except (WebSocketDisconnect, OSError):
                    break
            await asyncio.sleep(0.01)

    # Task to forward input from websocket to shell
    async def forward_input():
        try:
            while True:
                data = await websocket.receive_text()
                os.write(master_fd, data.encode())
        except WebSocketDisconnect:
            pass # Client disconnected

    output_task = asyncio.create_task(forward_output())
    input_task = asyncio.create_task(forward_input())

    try:
        await asyncio.gather(output_task, input_task)
    finally:
        # Cleanup
        output_task.cancel()
        input_task.cancel()
        os.close(master_fd)
        os.close(slave_fd)
        if shell_process.returncode is None:
            shell_process.terminate()
            await shell_process.wait()
        print("Interactive session closed.")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
