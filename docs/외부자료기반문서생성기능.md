"외부 자료 기반 문서 생성" 기능 구현 계획

  ---

  구현 계획: 외부 자료 기반 문서 생성 (External Data-based Document Generation) - 단위 테스트 포함

  목표: AI Agent가 외부 참조 사이트 및 기술 문서를 검색하여 지식 베이스 문서를 생성하는 기능을
  구현합니다.

  ---

  Phase 1: 백엔드 핵심 기능 (데이터 수집 및 AI 처리)

   1. API 엔드포인트 정의:
       * 새로운 API 엔드포인트 (POST /api/v1/knowledge/generate-from-external 등)를 생성하여 문서
         생성 요청을 받습니다. (쿼리/주제 입력, 생성된 문서 내용 반환 또는 비동기 작업 ID 반환)
       * 단위 테스트: 엔드포인트의 요청/응답 스키마 유효성 검사 및 기본 라우팅 동작에 대한 단위
         테스트를 작성합니다.
   2. 외부 데이터 검색 모듈 개발:
       * external_search_service.py와 같은 모듈을 개발하여 다음 기능을 수행합니다:
           * 검색 쿼리 처리.
           * 웹 검색 API (예: Google Search API) 또는 필요시 웹 스크래핑 솔루션과 연동.
           * 관련 URL 및 초기 콘텐츠 스니펫 검색.
       * 단위 테스트: 검색 쿼리 파싱, 외부 API 호출(모의 처리), 결과 필터링 및 정제 로직에 대한 단위
         테스트를 작성합니다.
   3. 콘텐츠 추출 및 전처리 모듈 개발:
       * content_extractor.py와 같은 모듈을 개발하여 다음 기능을 수행합니다:
           * 식별된 URL에서 콘텐츠를 가져옵니다 (예: requests 및 BeautifulSoup를 사용하여 HTML 파싱).
           * 추출된 텍스트를 정리하고 전처리합니다 (상용구, 광고, 탐색 요소 등 제거).
       * 단위 테스트: 다양한 HTML 구조에서 콘텐츠 추출, 텍스트 정제 규칙, 특정 요소 제거 로직에 대한
         단위 테스트를 작성합니다.
   4. AI 문서 생성 모듈 개발:
       * ai_document_generator.py와 같은 모듈을 개발하여 다음 기능을 수행합니다:
           * 전처리된 콘텐츠와 원본 쿼리를 입력으로 받습니다.
           * LLM (예: Gemini API)과 연동하여:
               * 콘텐츠 요약.
               * 핵심 정보 추출.
               * 구조화된 지식 베이스 문서 형식(예: Markdown)으로 변환.
               * 기존 문서에 대한 업데이트 제안 가능성 식별.
       * 단위 테스트: LLM 입력 프롬프트 구성, 응답 파싱, 마크다운 형식 변환, 업데이트 제안 로직(모의
         LLM 응답 사용)에 대한 단위 테스트를 작성합니다.
   5. 기존 백엔드 통합:
       * 새로운 모듈들을 기존 FastAPI 백엔드에 통합합니다.
       * 장시간 소요되는 생성 작업에 대해 비동기 처리(예: Celery/Redis 또는 FastAPI의 백그라운드
         태스크)를 고려합니다.
   6. 통합 테스트 (Phase 1):
       * API 엔드포인트를 검증하고, 데이터가 새로운 모듈을 통해 올바르게 흐르고 LLM 통합이 작동하는지
         확인합니다. (웹 검색, LLM 등 외부 서비스는 모의(mock) 처리하여 테스트)

  ---

  Phase 2: 프론트엔드 통합 및 사용자 경험

   1. 문서 생성 요청 UI:
       * 프론트엔드(Nuxt 3)에 새로운 UI 컴포넌트(예: 버튼 또는 폼)를 추가하여 사용자가 다음을 수행할
         수 있도록 합니다:
           * 문서 생성을 위한 주제/쿼리 입력.
           * 백엔드 API 호출 트리거.
       * 단위 테스트: UI 컴포넌트의 렌더링, 사용자 입력 처리, 이벤트 발생(버튼 클릭 등) 및 상태
         변화에 대한 단위 테스트를 작성합니다. (Vitest 사용)
   2. 생성된 콘텐츠 표시:
       * 구현된 UI 컴포넌트에서 생성된 문서 콘텐츠를 사용자에게 표시하는 메커니즘을 구현합니다. 이는
         다음 중 하나일 수 있습니다:
           * 검토 및 편집을 위한 에디터에 직접 표시.
           * 지식 베이스에 저장하기 전 미리보기로 표시.
       * 단위 테스트: 콘텐츠 표시 로직, 마크다운 렌더링, 편집기 연동(모의 데이터 사용)에 대한 단위
         테스트를 작성합니다.
   3. 지식 베이스 저장:
       * 기존 문서 저장 API를 통해 생성된 문서를 mcp_knowledge_base 디렉토리에 저장하는 기능을
         제공합니다.
       * 단위 테스트: 저장 API 호출(모의 처리), 성공/실패 응답 처리 로직에 대한 단위 테스트를
         작성합니다.
   4. 로딩/진행률 표시기:
       * 비동기 생성 프로세스에 대한 UI 피드백(예: 로딩 스피너, 진행 메시지)을 구현합니다.
       * 단위 테스트: 로딩 상태 변화에 따른 UI 요소 표시/숨김, 메시지 업데이트 로직에 대한 단위
         테스트를 작성합니다.
   5. E2E 테스트 (Phase 2):
       * Playwright를 사용하여 문서 생성을 트리거하고 콘텐츠의 표시 및 저장을 검증하는 사용자
         상호작용을 시뮬레이션합니다.

  ---

  Phase 3: 고급 기능 및 개선

   1. 자동 업데이트 제안/적용:
       * 새로 생성된 콘텐츠를 기존 지식 베이스 항목과 비교하고 업데이트를 제안하거나 자동으로
         적용(사용자 승인 워크플로우 포함)하도록 AI 생성 모듈을 개선합니다.
       * 단위 테스트: 콘텐츠 비교 알고리즘, 업데이트 제안 조건, 자동 적용 로직에 대한 단위 테스트를
         작성합니다.
   2. 출처 표기:
       * 생성된 문서 내에 생성에 사용된 외부 소스에 대한 참조/링크를 포함합니다.
       * 단위 테스트: 출처 정보 파싱 및 문서 내 삽입 로직에 대한 단위 테스트를 작성합니다.
   3. 오류 처리 및 재시도 메커니즘:
       * 외부 API 호출, 네트워크 문제, AI 모델 실패에 대한 견고한 오류 처리를 구현합니다.
       * 단위 테스트: 다양한 오류 시나리오(네트워크 오류, API 제한 초과 등)에 대한 오류 처리 및
         재시도 로직을 테스트합니다.
   4. 속도 제한 및 비용 관리:
       * 외부 서비스 및 LLM에 대한 API 호출 속도를 관리하고 비용을 모니터링하는 메커니즘을
         구현합니다.
       * 단위 테스트: 속도 제한 규칙 적용, 비용 계산 로직에 대한 단위 테스트를 작성합니다.

  ---

  주요 기술/도구:

   * 백엔드: FastAPI (Python), requests, BeautifulSoup (스크래핑 필요시), LLM API (Gemini),
     Celery/Redis (비동기 태스크).
   * 프론트엔드: Nuxt 3 (Vue.js), Tailwind CSS.
   * 테스팅: pytest (백엔드 단위/통합), Vitest (프론트엔드 단위), Playwright (프론트엔드 E2E).

  ---
