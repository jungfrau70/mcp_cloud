AI 에이전트와의 대화를 주제별로 관리하며 필요에 따라 시스템 명령어를 사용하는 통합적인 경험(UI/UX) 제공

사용자 시나리오: AI Agent & Shell 통합 터미널
이 시나리오는 개발자가 AI 에이전트와 대화를 나누며 코딩 작업을 하다가, 필요한 경우 직접 시스템 명령어를 실행하여 문제를 해결하는 과정을 보여줍니다.

새로운 대화 시작 (기본 대화 모드)

사용자는 브라우저를 열고 앱에 접속합니다.

입력창에 **"Python에서 웹 스크래핑하는 방법"**을 입력하고 엔터를 누릅니다.

백엔드는 이 요청을 AI 에이전트로 간주하고 새로운 대화 컨텍스트를 생성합니다.

AI 에이전트는 Python 웹 스크래핑에 대한 코드 예제와 설명을 응답으로 제공합니다.

대화 컨텍스트 유지

사용자는 **"requests 라이브러리를 사용해서 예제를 보여줘."**라고 추가 질문을 입력합니다.

프론트엔드는 이전 응답으로 받은 대화 ID를 함께 백엔드로 보냅니다.

AI 에이전트는 이 ID를 통해 이전 대화 내용을 기억하고, requests 라이브러리를 사용한 웹 스크래핑 예제를 이어서 제공합니다.

시스템 명령어 실행

AI 에이전트가 제공한 예제를 따라 해보려던 사용자는 컨테이너에 requests 라이브러리가 설치되어 있지 않다는 것을 알게 됩니다.

사용자는 터미널 모드로 전환하기 위해 입력창에 **/c pip install requests**를 입력하고 엔터를 누릅니다.

프론트엔드는 이 명령어를 시스템 명령어로 인식하고 백엔드에 전달합니다.

백엔드는 **subprocess**를 이용해 실제 컨테이너 내에서 pip install requests 명령어를 실행하고, 설치 성공 메시지를 프론트엔드로 반환합니다.

다른 주제의 대화 시작

웹 스크래핑 작업을 마무리한 사용자는 새로운 주제에 대해 궁금해집니다.

입력창에 **"쿠버네티스에서 서비스와 파드의 관계"**에 대해 질문합니다. 이때 별도의 대화 ID를 지정하지 않으므로, 백엔드는 새로운 대화 컨텍스트를 생성합니다.

AI 에이전트는 이 대화를 기존 스크래핑 대화와 분리하여 쿠버네티스에 대한 설명을 제공합니다.

이 시나리오는 하나의 입력창을 통해 유연한 작업 흐름을 제공하며, 사용자가 AI 에이전트의 도움을 받으면서 직접 시스템을 제어하는 능동적인 상호작용을 가능하게 합니다.

---

Nuxt3 Frontend 

<template>
  <div class="flex flex-col items-center justify-center min-h-screen bg-gray-900 text-gray-100 p-4">
    <div class="w-full max-w-2xl bg-gray-800 rounded-lg shadow-xl p-6">
      <h1 class="text-2xl font-bold mb-4 text-center">컨테이너 터미널 MVP (with AI Agent)</h1>

      <!-- 출력 영역과 복사 버튼 -->
      <div class="relative">
        <button
          @click="copyOutput"
          class="absolute top-2 right-2 bg-gray-600 hover:bg-gray-700 text-white font-bold py-1 px-3 rounded-lg text-xs opacity-75 hover:opacity-100 transition-opacity duration-200"
          title="출력 내용 복사"
        >
          복사
        </button>
        <div class="h-80 overflow-y-scroll bg-black text-green-400 font-mono text-sm p-4 rounded-lg mb-4 whitespace-pre-wrap select-text" ref="outputArea">
          <span class="text-gray-400">명령어는 /c로 시작하고, 그 외는 AI Agent와 대화합니다.</span>
          <div v-for="(line, index) in outputLines" :key="index">{{ line }}</div>
        </div>
      </div>

      <!-- 입력 영역 -->
      <div class="flex">
        <span class="text-green-400 font-mono mr-2">&gt;</span>
        <input
          type="text"
          v-model="command"
          @keyup.enter="runCommand"
          class="flex-1 bg-black text-green-400 font-mono text-sm outline-none border-b-2 border-transparent focus:border-green-400 transition-colors duration-200"
          :disabled="isLoading"
          placeholder="/c ls -l 또는 AI Agent에게 질문"
        />
      </div>
      <div v-if="isLoading" class="text-sm text-center text-gray-500 mt-2">
        명령어 실행 중...
      </div>
    </div>
  </div>
</template>

<script setup>
import { ref, nextTick } from 'vue';

// ref를 사용하여 반응형 상태 변수 선언
const command = ref('');
const outputLines = ref([]);
const isLoading = ref(false);
const outputArea = ref(null);
const conversationId = ref(null); // 대화 컨텍스트를 위한 ID

// 비동기 함수로 명령어 실행
async function runCommand() {
  if (isLoading.value || !command.value.trim()) {
    return;
  }

  const currentCommand = command.value;
  outputLines.value.push(`> ${currentCommand}`);
  command.value = '';
  isLoading.value = true;

  // 출력 영역을 맨 아래로 스크롤
  nextTick(() => {
    outputArea.value.scrollTop = outputArea.value.scrollHeight;
  });

  try {
    // 단일 엔드포인트(/agent)로 요청 전송
    const response = await fetch('http://localhost:8000/agent', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        user_input: currentCommand,
        conversation_id: conversationId.value // 대화 ID 함께 전송
      }),
    });

    if (!response.ok) {
      throw new Error(`API 오류: ${response.statusText}`);
    }

    const data = await response.json();

    // 백엔드에서 받은 새 대화 ID 저장 (새로운 대화일 경우)
    if (data.conversation_id) {
      conversationId.value = data.conversation_id;
    }

    // 결과 출력
    if (data.result) {
      outputLines.value.push(...data.result.split('\n'));
    }
    if (data.error) {
      outputLines.value.push(`오류: ${data.error}`);
    }
  } catch (error) {
    outputLines.value.push(`> 네트워크 오류: ${error.message}`);
  } finally {
    isLoading.value = false;
    nextTick(() => {
      outputArea.value.scrollTop = outputArea.value.scrollHeight;
    });
  }
}

// 출력 내용을 클립보드에 복사하는 함수
async function copyOutput() {
  const textToCopy = outputLines.value.join('\n');
  try {
    // navigator.clipboard.writeText는 iframe에서 보안 문제로 동작하지 않을 수 있습니다.
    // 이 경우 document.execCommand('copy') 또는 다른 방법을 사용해야 합니다.
    await navigator.clipboard.writeText(textToCopy);
    alert('출력 내용이 클립보드에 복사되었습니다.');
  } catch (err) {
    console.error('클립보드 복사 실패:', err);
    alert('클립보드 복사 실패: 지원되지 않는 브라우저이거나 권한 오류일 수 있습니다.');
  }
}
</script>

<style scoped>
/* Tailwind CSS 사용을 위한 스타일은 별도로 작성하지 않음. */
/* HTML 태그에 직접 Tailwind 클래스를 적용했습니다. */
</style>


---

Backend
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import subprocess
import os
import uuid

# Google Generative AI SDK를 사용해야 합니다.
# pip install google-generativeai
import google.generativeai as genai

# 아래 YOUR_API_KEY_HERE 부분을 실제 Gemini API 키로 교체하세요.
# https://aistudio.google.com/app/apikey 에서 키를 발급받을 수 있습니다.
# 보안을 위해 실제 앱에서는 환경 변수로 관리하는 것이 좋습니다.
API_KEY = "YOUR_API_KEY_HERE"
genai.configure(api_key=API_KEY)

# FastAPI 애플리케이션 초기화
app = FastAPI()

# CORS(Cross-Origin Resource Sharing) 설정
# 이 설정은 Nuxt.js 프론트엔드(localhost:3000)에서 백엔드(localhost:8000)로 API 호출을 허용합니다.
origins = ["http://localhost:3000"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic 모델을 사용하여 요청 본문의 유효성 검사
class InputPayload(BaseModel):
    user_input: str
    conversation_id: str = None

# 메모리 기반 대화 컨텍스트 관리
# 실제 운영 환경에서는 데이터베이스(Redis, Firestore 등)를 사용해야 합니다.
conversations = {}
model = genai.GenerativeModel('gemini-pro')

def get_conversation_context(conversation_id):
    """
    대화 ID에 해당하는 모델 채팅 세션을 반환합니다.
    새로운 ID이거나 세션이 없으면 새로 생성합니다.
    """
    if conversation_id not in conversations:
        conversations[conversation_id] = model.start_chat(history=[])
    return conversations[conversation_id]


@app.post("/agent")
async def handle_agent_input(payload: InputPayload):
    """
    사용자 입력을 받아 시스템 명령어 또는 대화 모드로 처리합니다.
    - '/c'로 시작하면 시스템 명령을 실행합니다.
    - 그 외의 경우는 AI 에이전트와 대화를 진행합니다.
    """
    user_input = payload.user_input.strip()

    # 시스템 명령어 모드: '/c'로 시작하는 경우
    if user_input.startswith('/c'):
        command = user_input[2:].strip()
        try:
            # 명령어 실행 시 안전을 고려하여 shell=True 사용에 유의해야 합니다.
            # 실제 프로덕션 환경에서는 subprocess.run의 shell=False를 사용하고
            # 명령어를 리스트 형태로 전달하는 것이 보안상 더 안전합니다.
            result = subprocess.run(
                command,
                shell=True,
                capture_output=True,
                text=True,
                timeout=10, # 명령어 타임아웃 설정 (10초)
                cwd=os.path.expanduser('~') # 홈 디렉토리에서 명령어 실행
            )

            if result.returncode == 0:
                return {"result": result.stdout}
            else:
                return {"error": result.stderr}

        except subprocess.CalledProcessError as e:
            return {"error": str(e)}
        except subprocess.TimeoutExpired:
            return {"error": "명령어 실행 시간이 초과되었습니다."}
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))}
            
    # 대화 모드: 기본 모드
    else:
        # 대화 ID가 없으면 새로 생성
        if not payload.conversation_id or payload.conversation_id not in conversations:
            conversation_id = str(uuid.uuid4())
            chat_session = get_conversation_context(conversation_id)
        else:
            conversation_id = payload.conversation_id
            chat_session = get_conversation_context(conversation_id)

        try:
            # AI 에이전트와 대화 진행
            response = await chat_session.send_message_async(user_input)
            
            # 응답과 함께 현재 대화 ID를 반환하여 프론트엔드가 컨텍스트를 유지하도록 함
            return {"result": response.text, "conversation_id": conversation_id}
        except Exception as e:
            return {"error": str(e), "conversation_id": conversation_id}

---