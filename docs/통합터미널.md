# 통합 터미널: AI 멘토와 함께하는 실습 환경

## 1. 개요

MentorAi의 통합 터미널은 학생들이 학습한 클라우드 기술을 즉시 실습해볼 수 있는 **대화형 학습 도구**입니다. 학생들은 학습 가이드에 나온 명령어를 직접 실행하고, 막히는 부분이 생기면 실시간으로 **AI 멘토**의 도움을 받을 수 있습니다.

## 2. 핵심 사용자 시나리오: S3 버킷 생성 실습

이 시나리오는 학생이 AWS S3 학습 모듈을 따라가며 통합 터미널을 사용하는 과정을 보여줍니다.

1.  **학습 내용 확인**: 학생이 'S3 시작하기' 학습 자료를 읽고 있습니다. 가이드에는 `aws s3 ls` 명령어로 현재 버킷 목록을 확인하는 내용이 있습니다.

2.  **기본 명령어 실습**: 학생이 학습 화면 하단의 통합 터미널에 `aws s3 ls`를 입력하고 실행합니다. 터미널에는 현재 버킷이 없다는 결과가 출력됩니다.

3.  **오류 발생**: 다음 가이드인 '버킷 생성'을 따라 학생이 터미널에 `aws s3 create-bucket my-unique-bucket` 이라고 잘못된 명령어를 입력합니다. (올바른 명령어는 `aws s3 mb s3://...`)

4.  **AI 멘토 호출**: AWS CLI는 오류 메시지를 출력합니다. 학생은 어떻게 해결할지 몰라 터미널에 `/ai help` 라고 입력하여 AI 멘토를 호출합니다.

5.  **AI 멘토의 도움**: AI 멘토가 학생의 마지막 명령어와 오류 메시지를 분석합니다.
    *   **AI 멘토 응답**: "'create-bucket'은 정확한 명령어가 아니에요. 버킷을 만들 때는 `mb`(make bucket) 명령어를 사용해야 합니다. 또한 버킷 이름은 `s3://` 형식으로 시작해야 해요. 이렇게 한번 시도해 보세요: `aws s3 mb s3://my-unique-bucket-12345`. 버킷 이름은 전 세계에서 유일해야 하니, 뒤에 임의의 숫자를 붙이는 것이 좋습니다. 관련 내용은 학습 자료의 '3.2. 버킷 생성하기' 섹션을 다시 참고해 보세요!"

6.  **문제 해결**: 학생은 AI 멘토의 가이드에 따라 올바른 명령어를 입력하여 성공적으로 버킷을 생성하고 다음 학습을 이어갑니다.

이 시나리오는 단순한 명령어 실행기를 넘어, 학생의 실습 과정에 AI 멘토가 개입하여 **교육적인 상호작용**을 만들어내는 통합 터미널의 핵심 가치를 보여줍니다.

## 3. 기술 구현 (UI/UX 관점)

-   **입력창**: 명령어와 AI 멘토 호출(`_명령어`)을 같은 입력창에서 처리하여 사용자 경험을 통일합니다.
-   **컨텍스트 인식**: AI 멘토는 학생의 최근 명령어, 오류 로그, 현재 학습 중인 콘텐츠의 맥락을 종합하여 답변을 생성합니다.

### 프론트엔드 (Nuxt 3)

```vue
<template>
  <!-- ... 터미널 UI ... -->
  <input
    type="text"
    v-model="command"
    @keyup.enter="runCommand"
    class="..."
    :disabled="isLoading"
    placeholder="학습 가이드의 명령어를 입력하거나 /ai 로 멘토에게 질문하세요"
  />
  <!-- ... -->
</template>

<script setup>
// ...
async function runCommand() {
  // ...
  // 백엔드의 단일 엔드포인트(/mentor/command)로 요청 전송
  const response = await fetch('http://localhost:8000/mentor/command', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      user_input: currentCommand, // 사용자가 입력한 전체 내용
      session_id: sessionId.value // 학생의 현재 학습 세션 ID
    }),
  });
  // ...
}
</script>
```

### 백엔드 (FastAPI)

```python
@app.post("/mentor/command")
async def handle_terminal_input(payload: InputPayload):
    user_input = payload.user_input.strip()
    session_id = payload.session_id

    # '/ai'로 시작하면 AI 멘토링 모드로 처리
    if user_input.startswith('/ai'):
        # 학생의 이전 명령어, 오류 로그 등 세션 정보를 가져옴
        context = get_student_session_context(session_id)
        question = user_input[3:].strip()
        
        # 컨텍스트와 함께 LLM에 전달하여 답변 생성
        response = await ai_mentor.get_answer(question, context)
        return {"response_type": "mentor_text", "content": response.text}
    
    # 그 외에는 실습 명령어로 간주하여 실행
    else:
        # 격리된 환경에서 명령어 실행
        result = await hands_on_lab.execute(user_input)
        # 실행 결과를 학생 세션 컨텍스트에 기록
        update_student_session_context(session_id, user_input, result)
        return {"response_type": "terminal_output", "content": result.stdout or result.stderr}
```
